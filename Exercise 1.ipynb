{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import bokeh as bk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of stations : Visualise missing data and sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv('exercise_data/example_sprit_cut_station.csv',sep=';')\n",
    "\n",
    "# Visualise number of missing entries\n",
    "msno.matrix(df_stations);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of stations : Clean data\n",
    "\n",
    "We observe that there are irrelevant columns and duplicates. Moreover, invalid values need to be dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['VERSION','VERSION_TIME','HOUSE_NUMBER','PUBLIC_HOLIDAY_IDENTIFIER']\n",
    "# Drop irrelevant columns\n",
    "df_stations.drop(cols_to_drop,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df_stations.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate about the null data\n",
    "null_data = df_stations[df_stations.isnull().any(axis=1)]\n",
    "null_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Invalid Streets and Places\n",
    "df_stations.update(df_stations[['STREET','PLACE']].fillna('Unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace invalid entries in postcode\n",
    "df_stations['POST_CODE'].fillna(value=0, inplace=True)\n",
    "df_stations['POST_CODE'].replace(to_replace=['\\\\N'],value='0',inplace=True)\n",
    "df_stations['POST_CODE'].replace(to_replace=['nicht'],value='0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean invalid brands\n",
    "inactive_brands=df_stations[df_stations['BRAND']=='nicht mehr aktiv']\n",
    "df_stations.drop(inactive_brands.index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN s and \\\\N s in brands\n",
    "df_stations['BRAND'].fillna(value='No Brand', inplace= True)\n",
    "df_stations['BRAND'].replace(to_replace=['\\\\N'],value='No Brand',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put brands and names in title case\n",
    "df_stations['BRAND'] = df_stations['BRAND'].str.title()\n",
    "df_stations['NAME'] = df_stations['NAME'].str.title()\n",
    "#Visualise unique brands\n",
    "sorted(df_stations.BRAND.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More brand cleaning\n",
    "df_stations.replace({'BRAND' : { '^Auto Zotz.*' : 'Auto Zotz', \n",
    "                                           '^Frei.*' : 'Freie Tankstelle',\n",
    "                                           '^Raiffeisen.*' : 'Raiffeisen Tankstelle',\n",
    "                                           '^Sb.*' : 'Sb Markt Tankstelle',\n",
    "                                           '^Supermarkt.*' : 'Supermarkt Tankstelle'\n",
    "                                            }},regex=True,inplace=True)\n",
    "#Visualise unique brands\n",
    "sorted(df_stations.BRAND.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'No name' brand can be replaced by names\n",
    "df_stations['BRAND']=np.where(df_stations['BRAND']== 'No Brand', df_stations['NAME'], df_stations['BRAND'])\n",
    "\n",
    "#Visualise unique brands\n",
    "sorted(df_stations.BRAND.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even more brand cleaning\n",
    "df_stations.replace({'BRAND' : { '^Autohaus Holz.*' : 'Autohaus Holz', \n",
    "                                           '^Eberhardt.*' : 'Eberhardt',\n",
    "                                           '^Globus Handelshof .*' : 'Globus Handelshof Gmbh & Co. Kg',\n",
    "                                           '^Sbk .*' : 'Sbk - Tankstelle',\n",
    "                                            }},regex=True,inplace=True)\n",
    "#Visualise unique brands\n",
    "sorted(df_stations.BRAND.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise number of missing entries\n",
    "msno.matrix(df_stations);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of prices: Visualise missing data and sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = pd.read_csv('exercise_data/example_sprit_cut_prices.csv',sep=';')\n",
    "# Visualise number of missing entries\n",
    "msno.matrix(df_prices);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of prices : Clean data\n",
    "We see that there are invalid prices along with duplicates. We need to normalise the dataset firstly and then perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df_prices.drop_duplicates(inplace=True)\n",
    "msno.matrix(df_prices);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5_invalid=df_prices[df_prices['E5']<=0]\n",
    "e5_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid prices from the data\n",
    "def remove_invalid_prices(fuel_name):\n",
    "    fuel_invalid=df_prices[df_prices[fuel_name]<=0]\n",
    "    df_prices.drop(fuel_invalid.index,axis=0,inplace=True)\n",
    "\n",
    "remove_invalid_prices('E5')\n",
    "remove_invalid_prices('E10')\n",
    "remove_invalid_prices('DIESEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the max, min are quite unrealistically bad. This needs normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(fuel_name):\n",
    "    data_mean, data_std = df_prices[fuel_name].mean(), df_prices[fuel_name].std()\n",
    "    # identify outliers upto 3 standard deviations\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "\n",
    "    df_prices[fuel_name]=np.where(np.logical_or(df_prices[fuel_name] <\n",
    "                                                lower,df_prices[fuel_name] > upper), \n",
    "                                  df_prices[fuel_name].median(), \n",
    "                                  df_prices[fuel_name])\n",
    "\n",
    "normalise_data('E5')\n",
    "normalise_data('E10')\n",
    "normalise_data('DIESEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
